European Journal of Work and Organizational Psychology

ISSN: 1359-432X (Print) 1464-0643 (Online) Journal homepage: https://www.tandfonline.com/loi/pewo20

Effectiveness of job crafting interventions: a metaanalysis and utility analysis
Bogdan Teodor Oprea, Liubița Barzin, Delia Vîrgă, Dragoș Iliescu & Andrei
Rusu
To cite this article: Bogdan Teodor Oprea, Liubița Barzin, Delia Vîrgă, Dragoț Iliescu & Andrei
Rusu (2019): Effectiveness of job crafting interventions: a meta-analysis and utility analysis,
European Journal of Work and Organizational Psychology, DOI: 10.1080/1359432X.2019.1646728
To link to this article: https://doi.org/10.1080/1359432X.2019.1646728

Published online: 05 Aug 2019.

Submit your article to this journal

Article views: 15

View Crossmark data

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=pewo20

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY
https://doi.org/10.1080/1359432X.2019.1646728

Eﬀectiveness of job crafting interventions: a meta-analysis and utility analysis
Bogdan Teodor Opreaa, Liubița Barzinb, Delia Vîrgăb, Dragoș Iliescu

a

and Andrei Rusu

b

a

Department of Psychology, University of Bucharest, Bucharest, Romania; bDepartment of Psychology, West University of Timisoara, Timisoara,
Romania
ABSTRACT

ARTICLE HISTORY

Job crafting (JC) is a form of bottom-up job design with a high potential for increasing work engagement and performance. For this reason, researchers have proposed interventions to stimulate JC in
organizations. The purpose of this paper was twofold: (1) to meta-analyse the eﬀectiveness of interventions on increasing JC behaviours, work engagement, and job performance; and (2) to estimate the
economic value of JC interventions, applying utility analysis. The systematic search identiﬁed 14 eligible
studies. Random-eﬀects meta-analyses revealed statistically signiﬁcant results on overall JC (g = 0.26;
95%CI [0.11, 0.40]), seeking challenges (g = 0.19; 95%CI [0.05, 0.33]), and reducing demands (g = 0.44;
95%CI [0.19, 0.69]), on work engagement (g = 0.31; 95%CI [0.14, 0.50]), and on contextual performance
(g = 0.39; 95%CI [0.01, 0.78]). Moderator analyses found that interventions in which participants formed
plans that included both organizational and personal objectives had moderate eﬀectiveness in boosting
work engagement; only healthcare employees reported gains in task performance. Any eﬀects of
enhancing JC behaviours on performance were fully explained by increases in work engagement.
Utility analysis indicated substantial beneﬁts regarding dollar value increases in output, the percentage
increase in output, and reduced labour costs for healthcare professionals.

Received 7 August 2018
Accepted 12 July 2019

Job design, as a solution for increasing employee performance
and well-being, represents one of the central areas of study in
work and organizational psychology (Parker, Morgeson, & Johns,
2017). However, classical top-down approaches of job design,
such as simpliﬁcation, standardization, or enrichment, led to
mixed results in terms of performance improvement and sometimes even to counter-productive behaviours (Oldham & Fried,
2016). Given these consequences, modern bottom-up
approaches have considered ways in which employees can
themselves design their jobs (Hornung, Rousseau, Glaser,
Angerer, & Weigl, 2010). For example, Daniels, Gedikli, Watson,
Semkina, and Vaughn (2017) conducted a systematic review of
interventions that aim to increase the well-being of workers
through job design and concluded that training employees to
improve their jobs by themselves is a promising method for
enhancing well-being and performance. Two of the interventions cited by Daniels et al. (2017) were based on teaching
employees how to craft their jobs. Job crafting (JC) represents
the changes made proactively by employees regarding their job
demands and job resources (Tims, Bakker, & Derks, 2012;
Wrzesniewski & Dutton, 2001). JC has been meta-analytically
shown to be associated with positive outcomes, including work
engagement and job performance (Rudolph, Katz, Lavigne, &
Zacher, 2017). These contributions encouraged the use of JC, as
a set of proactive behaviours, in performance enhancement and
human resources development.
Given these potential beneﬁts of JC, the number of studies
reporting on the development and eﬀectiveness of various JC
interventions has been steadily rising, from just one controlled
study in 2015 to eleven until 2018. However, to our knowledge,
CONTACT Andrei Rusu

andrei.rusu@e-uvt.ro

© 2019 Informa UK Limited, trading as Taylor & Francis Group

KEYWORDS

Job crafting; intervention;
meta-analysis; work
engagement; job
performance; utility analysis

no quantitative review of the results of JC interventions has been
published up to date. Since the literature in this ﬁeld has
increased, this paper expands on the extant systematic reviews
(e.g., Daniels et al., 2017) by quantitatively evaluating the eﬀectiveness of JC interventions. Therefore, the ﬁrst objective of the
current paper is to provide a systematization of the available data
and conduct a meta-analysis regarding the eﬃcacy of JC interventions. Secondly, we point to several authors (e.g., Boudreau &
Ramstad, 2002) who have described the apparent incapacity of
work and organizational psychology to provide actionable data
for strategic HRM decisions. They have also pointed to utility
analysis as one of the avenues through which such integration
between psychological data and HR decisions could be achieved.
In following this call, the second objective of this paper was to
conduct a utility analysis to estimate the economic value of JC
interventions for organizations. By addressing these objectives,
we expect to encourage researchers and practitioners to invest
further eﬀort in developing evidence-based interventions related
to JC.
This paper contributes to the job design literature in several
ways. Firstly, by conducting a meta-analysis, we reached a global
estimate of the eﬀect size of JC interventions, leading to a more
objective evaluation of their eﬀectiveness. Secondly, we examined
the impact of potential moderators and provided valuable information on how interventions should be carried out, and on what
groups of employees such interventions might have the greatest
impact. Finally, the results of the utility analysis highlight the
economic value of JC interventions, allowing us to understand if
and when they lead to a return on investment that exceeds the
short-term costs of their implementation.

2

B. T. OPREA ET AL.

JC, work engagement, and performance
JC is a form of bottom-up job design in which employees change,
based on their own initiative, the content or relational boundaries
of their jobs, even without explicit authorization from the
employer (Wrzesniewski & Dutton, 2001). They do so by increasing
resources and challenging demands and by reducing hindering
demands (Tims et al., 2012). The level of JC can vary from one
employee to another (Tims et al., 2012) and even from one day to
another for the same employee (Petrou, Demerouti, Peeters,
Schaufeli, & Hetland, 2012). There is also a diﬀerence in how JC
goals are being set: employees may decide the goals by themselves, a case in which they set individual objectives (e.g.,
Demerouti, Xanthopoulou, Petrou, & Karagkounis, 2017; Kooij,
van Woerkom, Wilkenloh, Dorenbosch, & Denissen, 2017), or
they may establish JC plans by also including deﬁned organizational objectives, hence are setting combined objectives (e.g.,
Gordon et al., 2018; Holman & Axtell, 2016).
Even though JC has been traditionally deﬁned based on two
competing perspectives (Demerouti, 2014; Le Blanc, Demerouti,
& Bakker, 2017), it was measured in research only based on one
of these. The ﬁrst perspective, developed by the American scholars Wrzesniewski and Dutton (2001), described JC as a series of
proactive changes in physical, cognitive, and relational job characteristics. According to them, job crafters change the job’s task
boundaries, the way they think about tasks and the interactions
they have with colleagues, supervisors, or clients. The second
perspective, which could be referred to as the Dutch approach,
relates JC to the Job Demands-Resources model (JD-R; Bakker &
Demerouti, 2007), and deﬁnes JC as a series of proactive behaviours aimed at seeking resources, seeking challenges, and reducing demands (Tims et al., 2012). The distinction between the
two perspectives is that the deﬁnition of Tims et al. (2012) is
centered explicitly on job characteristics and, unlike the deﬁnition of Wrzesniewski and Dutton (2001), that also includes the
cognitive processes and internal states related to task redeﬁnition, is focused only on external behaviours (Demerouti, 2014).
This distinction postulates diﬀerent measurement models, and it
is important enough to warrant diﬀerent measurement instruments for the two perspectives. The JD-R perspective has provided a reliable operationalization: Tims et al. (2012) developed
the Job Crafting Scale, that includes four independent JC dimensions (i.e., increasing structural job resources, increasing social
job resources, increasing challenging job demands, and decreasing hindering job demands). This instrument was later adopted
and sometimes adapted by other researchers (e.g., Petrou et al.,
2012). The Wrzesniewski and Dutton (2001) perspective has,
unfortunately, not provided a measurement instrument for JC
(Demerouti, 2014). Given this situation, JC was conceptualized
and measured in all empirical studies from the perspective of the
JD-R model. Accordingly, the JD-R model also served as the basis
for JC interventions. Hence, our ﬁrst question targets the eﬀectiveness of JC interventions for an increase in overall JC and its
components, as deﬁned by the JD-R model. If interventions have
an eﬀect on JC, then this may indicate that JC behaviours learned
in a training situation, later transfer to the job (Ford, Baldwin, &
Prasad, 2018). More broadly, this may suggest that it is possible
to transfer proactive behaviours from the context of learning into
daily work activities.

Research question 1: Are JC interventions eﬀective in enhancing
overall JC and its components (i.e., seeking resources, seeking
challenges, and reducing demands)?
Work engagement, deﬁned as “a positive, fulﬁlling workrelated state of mind that is characterized by vigour, dedication, and absorption” (Schaufeli, Salanova, González-Romá, &
Bakker, 2002, p. 74), is an important outcome because it is
associated with the ultimate criterion of job performance
(Bakker & Bal, 2010; Bakker, Demerouti, & Ten Brummelhuis,
2012; Christian, Garza, & Slaughter, 2011; Halbesleben &
Wheeler, 2008). Since the basis of JC interventions is the JDR model (see Bakker & Demerouti, 2007, 2014), we follow up
on one of the model’s predictions, namely that employees
who craft their jobs will have more job resources (Tims,
Bakker, & Derks, 2015a) and increasing resources will lead
to a higher level of work engagement (Bakker, Hakanen,
Demerouti, & Xanthopoulou, 2007; Bakker, Van Veldhoven,
& Xanthopoulou, 2010). Also, job demands amplify the
impact of resources on engagement (Hakanen, Bakker, &
Demerouti, 2005); therefore, increasing challenges should
also lead to a higher level of work engagement. In other
words, the acquisition of new resources and challenges
through JC will lead to engagement (Petrou et al., 2012).
This prediction was empirically supported in Rudolph et al.
(2017) meta-analysis, but only on correlational data, while
our aim is to seek support from studies with stronger designs
for causal inference. Hence, the second research question of
this meta-analysis investigates the eﬀectiveness of JC interventions in increasing work engagement.
Research question 2: Are JC interventions eﬀective in enhancing
work engagement?
The positive relationship between JC and job performance was
highlighted in qualitative interview studies (Berg, Wrzesniewski, &
Dutton, 2010; Lyons, 2008), quantitative survey studies (Bakker,
Tims, & Derks, 2012; Tims et al., 2012), and meta-analytically
(Rudolph et al., 2017). On the one hand, according to the JD-R
model (Bakker & Demerouti, 2014), JC leads to higher performance
because it increases the work engagement of employees. This
assumption regarding the mediating role of engagement is continuously supported by data (e.g., Tims et al., 2015a). On the other
hand, by crafting their jobs, employees can create an optimal work
environment, which contains the instrumental job resources that
are needed in achieving work objectives (Tims et al., 2015a).
Therefore, it is expected that they will have a higher level of
performance also as a direct consequence of JC. Hence, increasing
individual performance is arguably the goal of all JC interventions,
all the targeted constructs (behaviours, engagement), ultimately
leading to performance. JC interventions are generally aimed at
increasing three types of performance: task, adaptive, and contextual. Therefore, the third objective of this meta-analysis is to
investigate whether there is an increase in both overall and these
three types of performance following JC interventions.
Research question 3: Are JC interventions eﬀective in enhancing
overall job performance and its components (task, adaptive, and
contextual)?

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

Moderator variables for the eﬀectiveness of JC
interventions
Some intervention programs may be more eﬀective than
others, and some groups of employees may beneﬁt more
than others – it is essential to identify those factors that are
associated with the most signiﬁcant impact on outcomes. In
these regards, after reviewing the literature on JC interventions, we selected the type of objectives set in the intervention
(i.e., individual vs. combined) and participants’ occupations as
presumed moderators.

Objective of the intervention
As previously mentioned, there is a major diﬀerence between JC
interventions in how goals are set: they may be focused on
individual or combined objectives. Some of the interventions in
which the participants set individual objectives were based on
proactive goal setting (see Parker, Bindl, & Strauss, 2010), and the
process of generating future goals involved three steps: envisioning, planning, and proactive goal striving. During interventions,
participants envisioned a future in which they had more job
resources and a higher level of well-being, and they created an
action plan to achieve that future. The plan involved speciﬁc JC
behaviours, and employees strived to reach that future by crafting their jobs. This process was used in two interventions (Van
Wingerden, Bakker, & Derks, 2017a, 2017b), with positive results
on JC behaviours, work engagement, and job performance. In
other interventions that also included only individual objectives,
SMART (Speciﬁc, Measurable, Attainable, Results-oriented, and
Time-bound) goals were used (Demerouti et al., 2017; Dubbelt,
2016; Kooij et al., 2017). These interventions had mixed results on
JC behaviours, but they had positive results on increasing work
engagement (Dubbelt, 2016).
Regarding those interventions that included combined objectives, some of them used personal crafting plans (e.g., Gordon
et al., 2018; Van den Heuvel, Demerouti, & Peeters, 2015; Van
Mersbergen, 2012). JC plans consisted in speciﬁc crafting actions
formulated by the participants and scheduled for the next weeks
after the completion of the intervention. Also, objectives set by
the organization had been added to these plans (e.g., ﬁnding out
what budget is available to pursue a course). These programs
reported mixed results regarding the eﬀect on JC behaviours and
job performance, but positive results on increasing work engagement (Gordon et al., 2018; Van Mersbergen, 2012), contextual
performance (Gordon et al., 2018), and adaptive performance
(Van Mersbergen, 2012). In another intervention of this category,
Holman and Axtell (2016) reported that they used the scenario
planning method. Participants in the intervention discussed the
advantages and disadvantages associated with three possible job
design scenarios (i.e., aimed at maximizing well-being, aimed at
maximizing performance, or aimed at optimizing both) and
decided on adopting one of these strategies. This intervention
led to an increase in supervisor-rated job performance.
Given these mixed ﬁndings, we investigated which goal
setting methods are more eﬀective in stimulating JC behaviours, engagement, and performance: those in which employees only set their JC goals for themselves or those in which the
goals are combined (set both by the employees and the
company)? Therefore, our fourth research question is:

3

Research question 4: Does the eﬀectiveness of JC interventions diﬀer
as a function of the manner in which the objectives are set?

Occupation of participants
The JD-R model (Bakker & Demerouti, 2014) argues that diﬀerent
occupations may rely on speciﬁc combinations of job resources
and job demands. Therefore, distinct types of JC behaviours may
be performed diﬀerently across occupational groups (Nielsen &
Abildgaard, 2012). JC interventions have been tested on various
samples, such as medical staﬀ (e.g., Gordon et al., 2018), teachers
(e.g., Dubbelt, 2016), or police employees (Van den Heuvel et al.,
2015). The impact of JC interventions may diﬀer from one occupation to another due to each job’s speciﬁc characteristics, such as
personalized feedback for healthcare professionals or opportunities for professional development in the case of teachers
(Van Wingerden et al., 2017a). Also, a higher level of job autonomy
may facilitate a change in resources and demands (Petrou et al.,
2012). Indeed, nearly one-third of the variability in JC can be
attributed to the occupational context (Dierdorﬀ & Aguinis,
2018). Therefore, we checked whether interventions have
a diﬀerential impact on employees from speciﬁc professional
areas.
Research question 5: Does the eﬀectiveness of JC interventions
diﬀer between distinct occupations?

JC and performance: testing the indirect eﬀect of work
engagement
Since the JD-R model predicts that employees who craft their
jobs will have higher levels of work engagement (Bakker &
Demerouti, 2007; Hakanen et al., 2005; Petrou et al., 2012), and
work engagement will lead to job performance (Bakker & Bal,
2010; Bakker et al., 2012), it is expected that JC interventions will
increase employee job performance by increasing their work
engagement. Previous correlational data oﬀered support for
the mediated relationship between JC behaviours and task performance via work engagement (Bakker et al., 2012), ﬁndings
that were also replicated on teams (Tims, Bakker, Derks, & Van
Rhenen, 2013). Also, existing meta-analytical results support the
relationship between JC and both work engagement and job
performance (Rudolph et al., 2017). If the JD-R model is supported by our data, then the results of this meta-analysis will
identify that the increase in JC behaviours predicts the enhancement of work engagement, which in turn is associated with an
increase in performance. This indirect eﬀect illustrates the presumed mediational process that explains the way in which JC
interventions produce changes at a practical level (employee
performance). Hence, through our meta-analysis, we also aimed
at addressing the following research question:
Research question 6: Is the increase in JC behaviours indirectly
associated with an increase in employee performance through
the elevation of work engagement?

Utility analysis of JC interventions
Utility analysis, i.e., the assessment of the economic impact of
human resources practices by applying mathematical formulas

4

B. T. OPREA ET AL.

(Barrick, Day, Lord, & Alexander, 1991; Roth, Bobko, & Mabon,
2002), has three signiﬁcant beneﬁts. Firstly, this type of analysis allows human resources professionals to explain the value
of their practices eﬃciently (Boudreau, 1991; Highhouse, 1996;
Rauschenberger & Schmidt, 1987), including organizational
interventions (e.g., Arthur, Kyte, Villado, Morgan, & Roop,
2011). Secondly, utility analysis procedures may help decision
makers choose what HRM strategies to adopt (Cabrera & Raju,
2001), based on the expected ﬁnancial return on their investment in these strategies. Thirdly, the data indicates that managers respond more positively to information provided by
organizational psychology if it is presented in conjunction
with its likely ﬁnancial beneﬁts (Macan & Foster, 2004).
Therefore, we expect that the utility analysis of JC interventions will help decision makers to understand the monetary
beneﬁts of employee JC behaviours and lead to more rational
and productive choices about stimulating those behaviours at
work. In other words, utility analysis would increase the
chance for the adoption of JC interventions as essential tools
in the repertoire of HRM practices. Hence, we estimate the
economic value of JC interventions for organizations, applying
the principles and procedures of utility analysis to compute
the dollar value increase in output, the percentage increase in
output, and the reduced labour costs derived from JC
interventions.

Method
We followed the PRISMA framework (Moher, Liberati, Tetzlaﬀ, &
Altman, 2009; Shamseer et al., 2015) for conducting and reporting
the systematic review and meta-analytical procedures.

Eligibility criteria
In order to systematize study selection, we used the PICOS
approach (the acronym stands for: Population; Intervention;
Comparison; Outcome; Study type). Each study was required
to meet the following criteria to be included in the metaanalysis: (P) the samples to consist of employees; (I) the intervention program to be explicitly developed from the Job
Crafting theoretical perspective; (C) the study to include
a control group (i.e., waiting list, inactive or placebo comparison); (O) job crafting, work engagement and/or employee
performance to be among the monitored outcomes; (S) the
design to be experimental (between-group baseline equivalence attained through randomization) or quasi-experimental
(with no statistical diﬀerences between groups at baseline).
Moreover, the study had to include all the necessary information to compute eﬀect sizes, or at least to be retrievable from
other sources than the actual report. There were no restrictions regarding the form of the intervention (e.g., focused on
individuals or groups) or its duration.

Information sources
The search strategy relied on three information sources: (1) systematic search in electronic databases, (2) search in work and
organizational psychology conferences’ abstracts volumes, (3)
and contacting the main authors of published JC interventions.

The systematic search was conducted through the EBSCOhost
interface by interrogating the following exact databases:
Academic Search Complete, Business Source Complete, Education
Research Complete, ERIC, MEDLINE, Professional Development
Collection, Psychology and Behavioral Sciences Collection,
PsycINFO, Vocational and Career Collection. The abstracts volumes
were screened for the conferences and meetings organized by the
European Association of Work and Organizational Psychology,
European Academy of Occupational Health Psychology, Society
for Industrial and Organizational Psychology.

Literature search
The database search was conducted without a lower time limit
and until January 2018. The Boolean search was as follows: (“job
crafting” OR “job craft” OR “job crafter” OR “seek challenges” OR
“seeking challenges” OR “increase challenges” OR “increasing challenges” OR “decrease demands” OR “decreasing demands” OR
“reduce demands” OR “reducing demands” OR JD-R OR “job
demands-resources”) AND (trial or experiment* or quasi* random
or control) AND (intervention or treatment or program or strategy
or training or workshop). All terms related to JC were searched
only in abstracts (AB) while the other terms were searched
throughout the manuscript. Meanwhile, using Wrzesniewski and
Dutton (2001) work as a landmark for the emergence of job
crafting, we tracked conference volumes from the end of 2018
back until 2001. Finally, authors have been contacted via e-mail,
either to share unpublished data on JC interventions or to clarify
or provide more data on published studies.

Study selection
The process of study selection consisted in two steps: (1) screening the abstracts of identiﬁed records for presumed eligibility,
and (2) screening the full texts of the records selected in the
previous step. Abstracts’ screening was performed by two independent reviewers, and both results were intersected. In this
step, besides the abstracts commonly identiﬁed as eligible, we
also kept each one’s unique selections. Next, the full texts of the
records selected after abstracts’ screening were retrieved and
checked for eligibility. This process involved checking if each
study meets all the eligibility criteria and if reports all the
necessary data for computing or estimating the eﬀect size.

Data items and data collection
Firstly, each study was screened to identify the necessary data for
the computation of eﬀect sizes (e.g., means and standard deviations for outcomes, as well as the sample sizes of the experimental
and control groups). Secondly, the following characteristics and
variables were extracted for each eligible study: identiﬁcation data
(i.e., authors and year of publication); (P) participants’ occupation,
geographical area of the participants; (I) intervention objective
(i.e., individual or combined), intervention length (> 1 month or
≤ 1 month); (C) type of control group (i.e., inactive/no treatment,
placebo control, waiting list), (O) outcomes (i.e., JC, work engagement, performance), (S) randomization of participants and times
of measurement. Finally, the risk of bias assessment was performed (see the Risk of bias section).

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

The entire coding process was performed independently by
2 Ph.D. students. In order to calculate the degree of agreement between assessors, we computed the Cohen’s Kappa
statistic. Values ranging between 0.00–0.20 suggest slight
agreement, 0.21–0.40 mean fair agreement, 0.41–0.60 represent moderate agreement, 0.61–0.80 substantial, and
0.81–1.00 almost perfect agreement (Gwet, 2012). In our case
the results ranged between moderate (kappa = 0.42; for
length of the intervention) to almost perfect agreement
(kappa = 0.83; for control condition). Any case of diﬀerences
was re-examined by a third reviewer, and afterward, as the
standard practice requires, all three experts discussed the
discrepancies until 100% agreement was reached.

Risk of bias
Based on the Cochrane Collaboration tool (Higgins & Green,
2011), the risk of internal bias has been assessed by taking into
consideration the following criteria: sequence generation and
allocation concealment (selection bias), blinding of outcome
assessor (detection bias), incomplete outcome data (attrition
bias), selective outcome reporting (reporting bias), and other
potential threats to internal validity. Each aspect has been
evaluated for each study by assigning it either a “low risk” of
bias, “high risk” of bias or “unclear risk” of bias. For each
quality criteria, low risk of bias is attributed only when there
is a clear description in the manuscript of the way that speciﬁc
aspect was handled. For example, a low risk of bias for selection would be suggested by a clear description of the entire
process of randomization. If the allocation was not randomly
performed or participants switched places between groups
after randomization, then the study is at high risk of bias.
Finally, if the authors only mention (randomly) allocating participants but without detailing the procedure, then the study
is labelled as unclear. The more criteria with low risk of bias
a study meets, the higher is the quality (internal validity) of
that study.
Risk of bias assessment was also performed by two independent experts. The extent of their agreement ranged
between moderate (kappa = 0.43; for selective outcome
reporting) to substantial (kappa = 0.74; for sequence generation). Again, any incongruence between reviewers was consensually settled after being checked by a third expert.

Summary measures and synthesis of results
A random-eﬀects meta-analysis was conducted using the
Comprehensive Meta-Analysis 2.0 statistical package (Borenstein,
Hedges, Higgins, & Rothstein, 2009). The eﬃcacy of the interventions was expressed through Hedges’s g eﬀect size. This is
a measure of standardized mean diﬀerence that is corrected for
small sample bias (Hedges & Olkin, 1985). Its interpretation is the
same as for Cohen’s d (Cohen, 1988): eﬀect sizes of .20 are considered small, eﬀect sizes equal or larger than .50 are moderate,
and estimates of .80 or higher are large. For the trials with preintervention and post-intervention measures, we computed the
eﬀects size based on the mean diﬀerences from pre- to postintervention as the means within each group and the preintervention standard deviations (SDs) as the SDs within each

5

group (Morris, 2008). If the SDs for each group were unavailable
(only means were reported) but reported for the overall sample
(common SD), we used the pre-intervention common SD for computing the eﬀect size. In one case (Van Wingerden, Derks, & Bakker,
2017), the trial compared four diﬀerent groups (i.e., the JC intervention, a PsyCap intervention, a mixed intervention, and a control
group). For each of these groups, the authors reported only the
pre- and post-intervention means, while the SDs were reported for
the entire sample. Since we were interested only in the comparison
between the JC intervention and the control group, in order to
compute the eﬀect size for these diﬀerences, we used each group’s
mean and sample size, while for the SD we used the common one
(computed for the entire sample of four groups). Thus, the eﬀect
sizes for this case are rather approximations than accurate estimates. Where both the means and SDs for each group were
unavailable, but the correlations between the experimental condition (0 = no intervention, 1 = intervention) and outcomes at
post-intervention were reported, we extracted and converted the
correlation coeﬃcients into standardized diﬀerences in means.
Moreover, for each eﬀect size and the average ones, we reported
the standard error (SE), lower limit and upper limit estimates
(with a 95% conﬁdence interval), and the p-value of the Z test
(statistical test for the null hypothesis regarding the eﬀect).
To get a grasp on the heterogeneity of the eﬀects, we
computed and reported the Q statistic (tests if there is signiﬁcant unexplained variance in the true eﬀect sizes), τ2 (estimate of the between-study variance), and the I2 statistic
(expresses the proportion of the observed variance which is
true variance) (see Borenstein, Higgins, Hedges, & Rothstein,
2017; for details regarding heterogeneity in meta-analyses).

Additional analyses
The hypothesized moderators were tested using subgroup analyses based on a mixed-eﬀects model. This type of analysis is
suitable for categorical moderators and employs a randomeﬀects model within each subgroup, while between-subgroups
diﬀerences are tested for signiﬁcance based on a ﬁxed-eﬀects
model. We also tested the moderated eﬀect of the quality of the
included studies (coded as a numerical variable, i.e., the total
number of criteria for which a trial was ranked at low risk) on the
mean eﬀect size by using meta-regression analysis.
For the indirect relationship between the post-intervention
eﬀects on JC and the post-intervention eﬀects on performance
via the post-intervention eﬀects on work engagement, we
used regression analyses with the study as the unit of analysis.
The indirect eﬀect was tested based on 95% conﬁdence intervals bootstrapped from 1000 samples.
We performed publication bias analyses for overall JC, work
engagement, and overall performance. We analysed the funnel plots that display the eﬀect sizes against their standard
errors (Egger, Smith, Schneider, & Minder, 1997). In the case of
biased literature, the funnel plot has an asymmetric shape,
most often caused by the absence of studies with nonsigniﬁcant results. Moreover, we also computed Egger’s
regression intercept for the symmetry of the funnel plot.
Also, we employed the Duval and Tweedie trim and ﬁll procedure, which estimates the eﬀect size after considering publication bias.

6

B. T. OPREA ET AL.

Utility analysis
To estimate the ﬁnancial value of the interventions, we used
the procedures recommended by Cascio and Boudreau (2011).
First, we analysed the dollar value increase in output of JC
interventions. This value refers to an increase in revenue from
improved performance (ﬁnancial gains from the sale of the
ﬁnal output of the work, increased due to the adoption of JC).
Based on Schmidt (2013), we considered the following estimation of dollar value for JC interventions:
Dollar Value ¼ðTÞðNÞðSDyÞðNÞðCÞ

(1)

where T is the number of years the program is continued, N is
the number of employees included in the JC program, SDy is
the standard deviation of job performance in dollar value, and
C is the cost per employee for implementing the program.
More than that, we conducted a break-even analysis (Cascio &
Boudreau, 2011), in order to estimate the minimum cost per
employee from which the intervention would no longer be
cost eﬀective (i.e., the increase in revenue from improved
performance will be equal to or smaller than the cost of the
intervention).
Secondly, we computed the percentage increase in output,
which represents the average percentage increase in output
produced under JC conditions as compared to the baseline in
the control condition (the diﬀerence between the work output
of the group that participated in the intervention and the
work output of the control group, expressed as a percentage):
Percentage Increase ¼ðdÞðSDpÞ

(2)

where d is the eﬀect size of the program on increasing job
performance and SDp is the standard deviation of work output across employees as a percentage of mean output.
Finally, we computed the reduced labour costs (money saved
because fewer employees must be paid to produce the same
result). There are situations where the company does not need
higher productivity, but a smaller number of employees to produce the same output – e.g., in situations where there is no
market for additional output (Schmidt, 2013). We may estimate
the reduced costs of labour based on the percentage increase in
output (Schmidt, Hunter, Outerbridge, & Trattner, 1986), because
when employees have a higher level of productivity as a result of
an intervention, fewer employees are needed to produce the
same output; in this case, companies save money by paying
fewer employees for the same output.
Reduced Labor Costs ¼ 100  100=ð1 þ PercentageIncreaseÞ
(3)

Results
Selection and inclusion of studies
The initial search returned 114 records. After screening them,
we identiﬁed 14 abstracts as being potentially eligible. Out of
these, four articles were excluded for the following reasons: (1)
lack of relevant information for the meta-analysis (i.e., O’Shea,
Lynch, Molina, & Cullinane, 2016), (2) an article reported only
a trial protocol (i.e., Slemp, Kern, & Baker, 2017), (3) a study

had no control group (i.e., Sakuraya, Shimazu, Imamura,
Namba, & Kawakami, 2016), and (4) the study from
a dissertation thesis (i.e., Van Mersbergen, 2012) was also
reported in a later article (i.e., Gordon et al., 2018; Study 2)
and we kept only the later reference. Moreover, we identiﬁed
6 other potential studies from I/O psychology conferences’
programs. After contacting the authors, we received the
needed information for 3 additional studies. Finally, 14 studies
were included in the meta-analysis, out of which nine were
journal articles (one article reported two studies), 3 were
unpublished data from conference presentations, and 1 was
a dissertation thesis (see Figure 1).

Description of the sample of studies
A systematic overview of the studies’ characteristics is displayed in Table 1. Studies have taken place in diﬀerent countries. Most were carried out in The Netherlands (n = 9; i.e.,
Dubbelt, 2016; Gordon et al., 2018; Kooij, Van Woerkom, &
Kuijpers, 2018; Kooij et al., 2017; Van den Heuvel et al., 2015;
Van Wingerden, Bakker, & Derks, 2016; Van Wingerden et al.,
2017a, 2017b, 2017). One study was conducted in Belgium
(Verelst, de Cooman, van Laar, & Meussen, 2018), one in
Greece (Demerouti et al., 2017), one in Italy (Costantini,
Demerouti, Ceschi, & Sartori, 2018), and another one in the
United Kingdom (Holman & Axtell, 2016).
Regarding the composition of the samples, four studies
included medical staﬀ: medical specialists and nurses
(Gordon et al., 2018; Study 1 & Study 2), healthcare professionals (Van Wingerden et al., 2016), or healthcare organization employees (Kooij et al., 2018). Four studies have been
conducted in educational contexts: one on university teaching
positions and support staﬀ (Dubbelt, 2016), one on teachers
working in primary education schools (Van Wingerden et al.,
2017b), and two on teachers working in primary schools for
special education (Van Wingerden et al., 2017a, 2017). The
other six studies focused on employees from other areas:
social services workers (Demerouti et al., 2017), call centre
agents (Holman & Axtell, 2016), employees of a health insurance company (Kooij et al., 2017), employees of a police district (Van den Heuvel et al., 2015), social services and
manufacturing workers (Costantini et al., 2018), and working
mothers with various occupations (Verelst et al., 2018).
In most studies, JC was measured with the Petrou et al.
(2012) scale, that includes seeking resources, seeking challenges, and reducing demands (Costantini et al., 2018;
Demerouti et al., 2017; Dubbelt, 2016; Gordon et al., 2018;
Van den Heuvel et al., 2015). In two studies, the full version
of Job Crafting Scale (Tims et al., 2012) was used (Van
Wingerden et al., 2017a, 2017). Van Wingerden et al. (2016,
2017b) used a partial version of the Job Crafting Scale (Tims
et al., 2012), without the items focusing on decreasing hindering job demands. Kooij et al. (2017); (2018)) measured JC with
a scale that they had developed, focusing on two components: crafting toward strengths and crafting toward interest.
Finally, Verelst et al. (2018) used the Overarching Job Crafting
Scale (Vanbelle, 2016). Holman and Axtell (2016) did not measure JC, but they measured participants’ performance. Thus,
we included only this outcome in the meta-analysis.

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

7

Figure 1. Flow diagram of the systematic literature search.

Apart from the trial reported by Van Wingerden et al.
(2017a) in which a 1-year follow-up was employed, and
Costantini et al.’s (2018) trial which had three repeated measures, all the other studies had only post-intervention assessments (i.e., outcome evaluation was conducted shortly after
the intervention ended). Hence, the meta-analysis includes
only post-intervention eﬀects and not long-term eﬀects.
Moreover, we consider worth highlighting that the study
conducted by Demerouti et al. (2017) measured the eﬃcacy of
a JC intervention during a context of organizational change
due to austerity measures. Thus, this study has a unique feature that might have impacted the delivery of the intervention
and its eﬀectiveness.

Quality of the included studies
As summarized in Table 1 and displayed in Figure 2, we
registered a high risk related to sequence generation and
allocation concealment, as eleven out of thirteen studies
were quasi-experimental or lacked a full randomized assignment. Only two studies were labelled with a low risk of bias
(i.e., Holman & Axtell, 2016; Verelst et al., 2018). For example,
Holman and Axtell (2016) used cluster randomization, which
was done after the participants were recruited into the trial
and after they ﬁlled-in the baseline measures. Detection bias
had a low risk for more than half of the studies (n = 8), and an
unclear risk in the other four cases. Twelve studies were
assessed with low risk regarding attrition bias and only one
considered as unclear. Regarding reporting bias, ten studies
were evaluated with low risk, two with high risk, and one
unclear. For other potential threats, four out of ten studies
have been rated as unclear, mainly due to issues regarding the
sample (e.g., Gordon et al., 2018), and participants dropout
(i.e., Dubbelt, 2016), while one was considered at high risk,

since some participants had the possibility of switching
between experimental and control conditions (Kooij et al.,
2017). In summary, eleven out of thirteen studies were
assessed with a low risk of bias for at least half of the criteria
taken into consideration. At the same time, selection bias was
a concern in almost all cases (eleven out of thirteen). Hence,
even though, overall, the risk of bias across studies seems low,
we incline to consider it rather unclear.

Intervention eﬀectiveness on JC behaviours
The main meta-analytical results are presented in Table 2 and
displayed in Figure 3. These revealed statistically signiﬁcant
eﬀects on overall JC, g = 0.26, p = .001, 95% CI [0.11, 0.40], and
two of its subcomponents, namely seeking challenges,
g = 0.19, p = .009, 95% CI [0.05, 0.33], and reducing demands,
g = 0.44, p = .001, 95% CI [0.19, 0.69]. The eﬀect on seeking
resources was not statistically signiﬁcant, g = 0.21, p = .062,
95% CI [–0.01, 0.44]. The eﬀects on overall JC and seeking
challenges were quite homogeneous (ps for Qs > .050, τ2 and
I2 close to or equal to 0.0, and conﬁdence intervals stretched
from very small eﬀects to small ones). Contrariwise, seeking
resources and reducing demands had inconsistent eﬀects
(ps for Qs < .050, τ2 > 0.07, I2 above 60%, and eﬀects that
transcended multiple categories of magnitudes – e.g., from
null towards almost medium, for seeking resources).

Intervention eﬀectiveness on work engagement and
performance
A signiﬁcant and small increase was reported for work engagement (g = 0.31, p = .001, 95% CI [0.14, 0.50]; p for Q > .05, τ2 = 0.02;
I2 = 29.73%). For overall performance, which has been computed
by taking into consideration all types of operationalizations, the

Combined
Individual
Individual

United
Kingdom

Netherlands

Netherlands

Teachers

Teachers

Primary school
teachers

Working mothers with
various occupations

Van Wingerden
et al. (2017a)

Van Wingerden
et al. (2017b)

Van Wingerden
et al. (2017)

Verelst et al.
(2018)

Belgium

Netherlands

Netherlands

Individual

Individual

Individual

Individual

Individual

Netherlands

Netherlands

Combined

Netherlands

< 1 month

> 1 month

> 1 month

> 1 month

No intervention

No intervention

No intervention

No intervention

No intervention

No intervention

≤ 1 month
> 1 month

No intervention

> 1 month

No intervention

≤ 1 month

No intervention

≤ 1 month

No intervention
(active)

No intervention

≤ 1 month

> 1 month

No intervention

> 1 month

No intervention

≤ 1 month

Pre-test, post-test,
follow-up

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test,
follow-up

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test

Pre-test, post-test

Control condition
Measures
No intervention
Pre-test, post-test

Intervention
length
≤ 1 month

Job crafting
Work
engagement
Performance
Job crafting
Work
engagement
Performance
Job crafting
Work
engagement
Job crafting
Work
engagement
Performance
Job crafting

Job crafting

Job crafting
Work
engagement

Job crafting

Performance

Job crafting
Work
engagement
Performance

Job crafting
Work
engagement
Performance
Job crafting
Work
engagement
Performance

Job crafting
Performance

Outcomes
Job crafting
Work
engagement

Job crafting (Overarching Job Crafting Scale,
(Vanbelle, 2016)

Job crafting (Tims et al., 2012)
Work engagement (UWES, Schaufeli et al., 2006)
Performance (Williams & Anderson, 1991)

Job crafting (Tims et al., 2012)
Work engagement (UWES, Schaufeli et al., 2006)

Job crafting (Tims et al., 2012)
Work engagement (UWES, Schaufeli et al., 2006)
Performance (Williams & Anderson, 1991)

Job crafting (Tims et al., 2012)
Work engagement (UWES, Schaufeli et al., 2006)
Performance (Williams & Anderson, 1991)

Job crafting (Kooij et al., 2017)
Work engagement (UBES – Utrechtse
Bevolgenheids Schaal developed by
Schaufeli & Bakker, 2003)
Job crafting (Petrou et al., 2012)

Job crafting (self developed scale)

Job crafting (Petrou et al., 2012)
Work engagement (UWES, Schaufeli et al., 2006)
Adaptive performance (Metselaar, 1997)
Task and contextual performance (Goodman
&Svyantec, 1999)
Job crafting (Petrou et al., 2012)
Work engagement (UWES, Schaufeli et al., 2006)
Adaptive performance (Griﬃn et al., 2007)
Task and contextual performance (Williams &
Anderson, 1991)
Objective performance (speciﬁc)
Job performance (Williams & Anderson, 1991)

Job crafting (Petrou et al., 2012)
Adaptive performance (Individual Task
Adaptivity Scale - Griﬃn et al., 2007)
Job crafting (Petrou et al., 2012)
Work engagement (UWES, Schaufeli et al., 2006)
Task performance (Xanthopoulou et al., 2008)

Operationalization of outcomes
Job crafting (Petrou et al., 2012)
Work engagement (UWES – Italian version,
Balducci, Fraccaroli, & Schaufeli, 2010)

Note: Risk of bias = risk of internal bias as resulted from the quality assessment (low / unclear / high = total criteria where the study was identiﬁed as being at low / unclear / high risk of bias).

Dutch police district
employees
Healthcare
professionals

Van den Heuvel
et al. (2015)
Van Wingerden
et al. (2016)

Civil Service
employees (call
center)
Kooij et al. (2017) Health insurance
employees
Kooij et al. (2018) Healthcare
organization
employees

Holman & Axtell
(2016)

Combined

Combined

Individual

Netherlands

Netherlands

Combined

Gordon et al.
Nurses
(2018); Study 2

Dubbelt (2016)

Greece

Netherlands

University staﬀ

Demerouti et al.
(2017)

Country
Italy

Gordon et al.
Medical specialist
(2018); Study 1

Sample
Employees working
for diﬀerent
organizations (i.e.
social services,
manufacturing)
Employees of a
municipality

Study
Costantini et al.
(2018)

Intervention
objective
Individual

Table 1. Characteristics of the sample of studies included in the meta-analysis.

4

3

3

4

4

3

3

3

6

2

2

3

3

2

0

0

0

0

1

0

0

0

2

2

1

1

0

3

3

2

2

2

3

3

0

2

2

2

2

Low Unclear High
1
4
1

Risk of bias

8
B. T. OPREA ET AL.

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

9

Figure 2. Risk of internal bias summary.

Table 2. Eﬀectiveness of the interventions for all the outcomes.
Outcome
Job crafting
Seeking resources
Seeking challenges
Reducing demands
Work engagement
Performance
Task/in-role performance
Adaptive performance
Contextual performance

k
13
10
10
8
9
8
6
3
2

n (int)
522
405
405
321
381
293
240
110
80

n (con)
558
367
367
313
332
288
207
139
97

g
0.26
0.21
0.19
0.44
0.31
0.22
0.19
0.35
0.39

SE
0.07
0.12
0.07
0.13
0.09
0.15
0.17
0.24
0.19

95% CI
0.11, 0.40
–0.01, 0.44
0.05, 0.33
0.19, 0.69
0.14, 0.50
–0.07, 0.51
–0.13, 0.52
–0.12, 0.81
0.01, 0.78

p
.001
.062
.009
.001
.001
.133
.232
.146
.048

Q(df)
16.92(12)
21.65(9)**
7.14(9)
16.60(7)*
11.38(8)
19.90(7)**
13.83(5)*
6.27(2)*
1.53(1)

τ2
0.02
0.08
0.00
0.07
0.02
0.11
0.10
0.11
0.03

I2
29.07
58.42
0.00
57.84
29.73
64.83
63.83
68.12
34.71

Notes: k = number of studies included in the analysis; n (int) = number of participants in the intervention group; n (con) = number of participants in the control
group; g = average eﬀect size; SE = standard error of the average eﬀect size; 95% CI = minimum and maximum limits of the 95% conﬁdence interval;
Q = statistical test for the estimation of heterogeneity; τ2 = between-study variance; I2 = proportion of observed eﬀects variation that is due to true eﬀects
variation (%).
*p < .05; **p < .01

results do not show a statistically signiﬁcant eﬀect (g = 0.22,
p = .133, 95% CI [–0.07, 0.51]). Consequently, non-signiﬁcant
eﬀects were revealed for task performance (g = 0.19, p = .232,
95% CI [–0.13, 0.52]) and adaptive performance (g = 0.35,
p = .146, 95% CI [–0.12, 0.81]). However, statistically signiﬁcant
results were obtained for contextual performance, g = 0.39,
p = .048, 95% CI [0.01, 0.78]. Important to notice that both overall
performance and the other two types with non-signiﬁcant
eﬀects are highly heterogeneous (ps for Qs < .05, τ2 > 0.10,
I2 above 60%, and eﬀects cut across very small and negative
indices towards positive medium or even large ones), but the
samples of studies, especially for the subtypes of performance,
are very small. Moreover, the contextual performance was averaged from only two studies, which makes this eﬀect even less
reliable.

Moderator analyses
Heterogeneity analysis revealed elevated inconsistencies for the
eﬀects of the interventions on JC (especially two of its dimensions;
i.e., seeking resources and reducing demands) and performance,
both overall and the subtypes. However, from the latter category,
adaptive performance (k = 3) and contextual performance (k = 2)
were already based on very small samples of studies. Also, some
inconsistencies seem to be present within the eﬀects on work
engagement. Hence, in the moderator analyses, we focused our
attention especially on the variables that were heterogeneous and
had enough studies for sub-group analyses (i.e., overall JC and its
subdimensions; work engagement; overall performance and task
performance). Moreover, we tested the moderator role of study
quality on all three main outcomes (i.e., JC, work engagement, and
performance), to inspect if the studies’ eﬀects sizes were biased by

their quality. As revealed in the literature (Hempel et al., 2011),
studies with precarious internal validity tend to produce overestimated eﬀect sizes.

Objective of the intervention as moderator

We considered studies with “individual” objectives to be
those where the goals of the crafting plan were set by
participants in line with their work-related needs, and “combined” to be those where the crafting plans represent
a combination between organizational goals and individual
needs. As can be seen in Table 3, results indicated that the
single signiﬁcant diﬀerence was for work engagement. The
mixed interventions (k = 2; g = 0.63, 95% CI [0.33, 0.94],
p < .001; Q(1) = 0.20, p = .658; τ2 = 0.00; I2 = 0.00) were
signiﬁcantly superior than the individual ones (k = 7;
g = 0.20, 95% CI [0.03, 0.38], p = .019; Q(6) = 5.39, p = .495;
τ2 = 0.00; I2 = 0.00) in enhancing participants’ engagement
(Qbetween (1) = 5.80, p = .016). There were no signiﬁcant diﬀerences between the eﬀects of individual and combined interventions regarding overall JC (Qbetween (1) = 0.02, p = .899), or
its components (Qbetween (1) = 0.07, p = .789 for seeking
resources; Qbetween (1) = 0.08, p = .775 for seeking challenges;
Qbetween (1) = 0.80, p = .372 for decreasing demands). The type
of objective did not have a signiﬁcant eﬀect on overall performance (Qbetween (1) = 1.59, p = .207), or task performance
(Qbetween (1) = 3.03, p = .082).

Participants’ occupation as a moderator
The meta-analysed studies included education employees
(k = 4), healthcare professionals (k = 4), and various other
occupations (k = 6). Even though the latter category includes
almost half the studies, all the occupations grouped in it are

10

B. T. OPREA ET AL.

Figure 3. Standardized eﬀect sizes and forest plots for the entire sample of studies for each of the three main outcomes.

unique. As reported in Table 4, the moderation eﬀect was not
signiﬁcant on overall JC (Qbetween (2) = 0.44, p = .804), and
neither on any of the subcomponents (Qbetween (2) = 2.92,
p = .232 for seeking resources; Qbetween (2) = 3.85, p = .146 for
seeking challenges; Qbetween (2) = 3.47, p = .176 for decreasing
demands). Moreover, there was also a non-signiﬁcant diﬀerence between occupational categories regarding the eﬀect on
work engagement (Qbetween (1) = 0.81, p = .369).
The eﬀectiveness on overall performance was not signiﬁcantly diﬀerent between the identiﬁed occupations
(Qbetween (2) = 4.57, p = .102). Instead, the eﬀect on task
performance was signiﬁcantly moderated by occupation
(Qbetween (1) = 4.65, p = .031). In this case, there were only
employees from education and healthcare. The eﬃcacy of the
interventions on healthcare employees produced signiﬁcant
and small to moderate increases in task performance (k = 3;
g = 0.47, 95% CI [0.21, 0.73], p < .001; Q(2) = 0.09, p = .955;

τ2 = 0.00; I2 = 0.00), while the eﬀect on educational personnel
was not signiﬁcant and still inconsistent (k = 3; g = – 0.09, 95%
CI [–0.52, 0.35], p = .698; Q(2) = 4.64, p = .098; τ2 = 0.08;
I2 = 56.89). It is important to mention that task performance
was the only type of performance that was assessed for the
latter category of employees.

Study quality as a moderator
We conducted separate meta-regressions with study quality (i.e.
total number of internal bias criteria at which each study was at low
risk; range: 1–6, median = 3) as predictor for each of the three
major outcomes (overall JC, work engagement, and overall performance). The eﬀect on overall JC was not statistically signiﬁcant
(b = 0.15, SE = .22, 95% CI [–0.28, 0.57], p = .504); the eﬀect on work
engagement was not statistically signiﬁcant (b = 0.30, SE = 0.23,
95% CI [–0.15, 0.76], p = .193); also, the eﬀect on overall performance was non-signiﬁcant (b = 0.02, SE = 0.07, 95% CI [–0.13, 0.16],

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

11

Table 3. Subgroup analyses investigating diﬀerences in eﬀects based on the types of objectives that participants had to set.
n(int)

sn(con)

g

SE

95% CI

p

Q(df)

τ2

I2

Qbetween(df)

p

373
149

372
186

0.26
0.24

0.09
0.15

0.09, 0.44
–0.06, 0.55

.004
.114

11.39(8)
5.49(3)

0.02
0.04

29.75
45.37

0.02(1)

.899

256
149

181
186

0.19
0.28

0.01
0.29

0.01, 0.38
–0.29, 0.85

.049
.345

2.38(5)
19.29(3)**

0.00
0.28

0.00
84.44

0.07(1)

.789

256
149

181
186

0.21
0.16

0.10
0.14

0.02, 0.40
–0.12, 0.44

.034
.269

2.24(5)
4.84(3)

0.00
0.03

0.00
37.99

0.08(1)

.775

Reducing demands
Individual
4
Combined
4

117
149

86
186

0.57
0.33

0.22
0.16

0.15, 0.99
0.02, 0.65

.008
.040

9.42(3)*
6.09(3)

0.12
0.05

68.17
50.78

0.80(1)

.372

Work engagement
Individual
7
Combined
2

301
80

235
97

0.20
0.63

0.09
0.16

0.03, 0.38
0.33, 0.94

.019
< .001

5.39(6)
0.20(1)

0.00
0.00

0.00
0.00

5.80(1)

.016

Overall performance
Individual
4
Combined
4

160
133

110
178

0.04
0.39

0.21
0.18

–0.36, 0.45
0.03, 0.75

.841
.034

7.96(3)*
7.05(3)

0.10
0.08

62.30
57.47

1.59(1)

.207

Task/in-role performance
Individual
4
160
Combined
2
80

110
97

0.04
0.49

0.21
0.16

–0.36, 0.45
0.19, 0.79

.841
.002

7.96(3)*
0.04(1)

0.10
0.00

62.30
0.00

3.03(1)

.082

Outcome
k
Overall job crafting
Individual
9
Combined
4
Seeking resources
Individual
6
Combined
4
Seeking challenges
Individual
6
Combined
4

Notes: k = number of studies included in the analysis; n (int) = number of participants in the intervention group; n (con) = number of participants in the control
group; g = average eﬀect size; SE = standard error of the average eﬀect size; 95% CI = minimum and maximum limits of the 95% conﬁdence interval;
Q = statistical test for the estimation of heterogeneity; τ2 = between-study variance; I2 = proportion of observed eﬀects variation that is due to true eﬀects
variation (%).
*p < .05; **p < .01
Table 4. Subgroup analyses investigating diﬀerences in eﬀects based on participants’ occupations.
n(int)

n(con)

g

SE

95% CI

p

Q(df)

τ2

I2

Qbetween(df)

p

158
168
196

116
175
167

0.27
0.31
0.18

0.12
0.11
0.16

0.03, 0.52
0.10, 0.53
–0.13, 0.50

.027
.005
.252

2.04(3)
2.93(3)
11.35(4)*

0.00
0.00
0.08

0.00
0.00
64.75

0.44(2)

.804

Seeking resources
Education
4
Healthcare
3
Other
3

158
123
114

116
121
130

0.18
0.55
–0.02

0.12
0.35
0.13

–0.06, 0.42
–0.13, 1.23
–0.26, 0.23

.145
.113
.899

2.26(3)
12.26(2)**
1.45(2)

0.00
0.29
0.00

0.00
83.69
0.00

2.92(2)

.232

Seeking challenges
Education
4
Healthcare
3
Other
3

158
123
114

116
121
130

0.19
0.38
0.02

0.12
0.13
0.13

–0.05, 0.44
0.12, 0.64
–0.23, 0.27

.112
.004
.878

1.52(3)
1.37(2)
0.38(2)

0.00
0.00
0.00

0.00
0.00
0.00

3.85(2)

.146

Outcome
k
Overall job crafting
Education
4
Healthcare
4
Other
5

Reducing demands
Education
3
Healthcare
2
Other
3
Work engagement†
Education
4
Healthcare
4

117
80
114

86
97
130

0.73
0.49
0.18

0.26
0.16
0.17

0.21, 1.24
0.19, 0.79
–0.16, 0.52

.006
.001
.308

6.02(2)*
0.08(1)
3.76(2)

0.13
0.00
0.04

66.76
0.00
46.81

3.47(2)

.176

158
223

116
216

0.27
0.45

0.12
0.16

0.03, 0.51
0.14, 0.76

.026
.004

1.63(3)
5.76(3)

0.00
0.05

0.00
47.89

0.81(1)

.369

Overall performance
Education
3
Healthcare
3
Other
2

117
123
53

86
121
81

–0.09
0.47
0.31

0.22
0.13
0.45

–0.52, 0.35
0.21, 0.73
–0.57, 1.19

.698
< .001
.491

4.64(2)
0.09(2)
6.14(1)*

0.08
0.00
0.34

56.89
0.00
83.71

4.57(2)

.102

Task/in-role performance
Education
3
117
Healthcare
3
123

86
121

–0.09
0.47

0.22
0.13

–0.52, 0.35
0.21, 0.73

.698
< .001

4.64(2)
0.09(2)

0.08
0.00

56.89
0.00

4.65(1)

.031

Notes: k = number of studies included in the analysis; n (int) = number of participants in the intervention group; n (con) = number of participants in the control
group; g = average eﬀect size; SE = standard error of the average eﬀect size; 95% CI = minimum and maximum limits of the 95% conﬁdence interval;
Q = statistical test for the estimation of heterogeneity; τ2 = between-study variance; I2 = proportion of observed eﬀects variation that is due to true eﬀects
variation (%). †For work engagement, the “Other” category contained only one study, thus was not included in the comparison.
*p < .05; **p < .01

p = .815). Hence, study quality was not a statistically signiﬁcant
moderator for any of the outcomes. When interpreting these
results, it is important to consider that the number of studies is
small for each of the three outcomes (k range between 7 and 14).

Indirect eﬀect
The indirect eﬀect was analysed on data extracted from only six
studies (i.e., Dubbelt, 2016; Gordon et al., 2018, Study 1 & 2; Van

12

B. T. OPREA ET AL.

Wingerden et al., 2016, 2017, 2017a). These were the only ones to
measure all three outcomes. As previously stated, we expected
that the post-intervention eﬀect on JC relates indirectly to the
post-intervention eﬀect on overall performance through the
eﬀect on work engagement (also measured in the post-test).
First, the total eﬀect of JC on performance was not statistically
signiﬁcant (b = 1.74, SE = 0.87, 95% CI [–0.69, 4.15], p = .117).
Moreover, as can be seen in Figure 4, the relationship between JC
and work engagement was partially signiﬁcant (b = 1.11,
SE = 0.51, 95% CI [–0.30, 2.53], p = .094), while work engagement
signiﬁcantly predicted performance (b = 1.50, SE = .47, 95% CI
[0.01, 3.01], p = .049), and the direct eﬀect of JC on performance
was still non-signiﬁcant (b = 0.06, SE = 0.71, 95% CI [–2.19, 2.32],
p = .934). Finally, and most importantly, the indirect eﬀect of JC
on performance was statistically signiﬁcant (b = 1.67, SE = 0.96,
95% CI [0.16, 3.58], p = .020). All the paths for the indirect
relationship were tested based on two-tailed signiﬁcance levels.
Hence, the hypothesized indirect eﬀect received support from
the data.

Publication bias
For JC eﬀects (k = 13), Egger’s test was not signiﬁcant (intercept = 0.85; p = .767, 95% CI [−5.28, 6.97]). The Duval and
Tweedie trim and ﬁll procedure imputed no studies, and the funnel
plot showed only a slight asymmetry (Figure 5). For work engagement (k = 9), Egger’s test was not signiﬁcant (intercept = 2.89;
p = .365, 95% CI [−4.18, 9.79], the Duval and Tweedie procedure
imputed no studies, and the funnel plot showed a symmetric
distribution. For performance (k = 8), Egger’s test was not signiﬁcant (intercept = 2.14; p = .674, 95% CI [−9.73, 14.02]), the Duval

and Tweedie trim and ﬁll procedure did not impute any studies,
and the funnel plot showed a relatively symmetric distribution. All
funnel plots can be inspected in Figure 5. Overall, each of the three
indicators suggests that publication bias is rather absent. Hence,
corroborating these ﬁndings with the fact that the sample includes
both published (k = 10) and unpublished (k = 4) data, we can
conclude that publication bias was not a concern for this metaanalysis.

Utility analysis of JC interventions
In order to conduct the utility analysis, we used the most reliable
eﬀect revealed by the meta-analysis. More precisely, we selected
the eﬀect that met the following two cumulative criteria: to be
homogeneous and statically signiﬁcant. The only eﬀect that satisﬁed both conditions was the one on task performance for healthcare professionals (k = 3). The overall eﬀect size is g = 0.47 (95% CI
[0.21, 0.73]; p < .001), which represents small to medium
eﬀectiveness. The test of heterogeneity was non-signiﬁcant
(Q(2) = 0.09, p = .955), and the amount of heterogeneity was
estimated at τ2 = 0.00. The I2 statistic also indicated 0.0% variability.
Considering that the longest study regarding the eﬀectiveness
of JC interventions on the job performance of healthcare professionals was conducted over a three-months period (Gordon et al.,
2018), and the results showed a signiﬁcant increase in job performance three months after the intervention, we have chosen the
value of .25 for T (three months of a year means 25% of a year).
There are no studies that show the impact of interventions over
a longer period. We made estimations for a single employee. The
formula for computing the dollar value for a performance increase,
before subtracting costs, is (d)(SDy) per employee. We have

Figure 4. The indirect relationship between the eﬀects on overall job crafting and those on overall performance through the eﬀects on work engagement.
Notes. † < .10; * < .05, n.s. = non-signiﬁcant. Standardized coeﬃcients (β) are displayed on each relationship.

Figure 5. Funnel plots for publication bias.

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

estimated SDy to be 40% of the employee’s salary (Hazer &
Highhouse, 1997). Based on the results of our meta-analysis, we
consider d to be 0.47 for healthcare employees. Given that
Hedges’s g is a measure of standardized mean diﬀerence that is
corrected for small sample bias (Hedges & Olkin, 1985), it can
replace Cohen’s d in the mathematical equation presented earlier.
Based on Schmidt (2013), we chose an annual salary of $50,000 for
our computation. Therefore, the dollar value increase in output is
(0.47)(0.40)($50,000) = $9400/year per employee (before subtracting costs) as a result of a JC intervention. Using the values in
Schmidt (2013), we chose a value of $40 for C. JC interventions
represent a relatively new concept in the ﬁeld, and few practitioners provide such human resources management services, so it
is challenging to estimate the real cost of such an intervention. We
have looked at the costs of interventions involving similar practices
(e.g., establishing work-related objectives), and we have chosen
the value proposed by Schmidt (2013). Therefore:
Dollar Value ¼ ð0:25Þð$9400Þð$40Þ
¼ $2; 310=three months=employee
Since the eﬀectiveness of the intervention may vary from one
situation to another, we have also calculated its impact based on
conﬁdence intervals (g = 0.47, 95% CI [.21, .73]). For the lower limit
(g = 0.21), the dollar value increase in output would be $1,010/
three months/employee, and for the highest one (g = 0.73), it
would be $3,610/three months/employee. Considering that the
cost per person was estimated based on the values used in other
types of interventions, we followed the recommendations of
Cascio and Boudreau (2011) and conducted a break-even analysis.
This analysis is the estimation of the smallest or the highest value
of any given parameter that will generate a positive utility or
payoﬀ. In our case, the break-even analysis allows us to estimate
the minimum cost per employee from which the intervention
would no longer be proﬁtable (i.e., it will lead to no increase in
revenue from improved performance). Based on our calculations, it
turns out that for an annual salary of $50,000 the cost of the
intervention per employee should not exceed $2,350, for an
annual salary of $40,000 it should not exceed $1,880, for $30,000
it should not exceed $1,410, and for $20,000 it should not exceed
$940. For lower costs than those presented, interventions should
be proﬁtable (i.e., should break-even).
As already mentioned, d is equal to 0.47 for healthcare
employees. Regarding SDp, Hunter, Schmidt, and Judiesch
(1990) computed it on a massive volume of data and showed
that it depends signiﬁcantly on the job level. For unskilled
jobs, SDp is 0.20, meaning that those unskilled employees
who are one standard deviation above the mean produce
20% more than the average employee. For mid-level jobs,
SDp is 0.30, and for professional/managerial jobs SDp is 0.50.
Given that studies in which the eﬀectiveness of JC interventions was tested have included doctors or nurses, we have
chosen the 0.30 value for SDp. Therefore:
Percentage Increase ¼ ð0:47Þð0:30Þ ¼ 0:141
¼ 14:10%=three months
As already computed, the percentage increase in output is
14.10% for three months after the intervention. Therefore:

13

Reduced Labor Costs ¼ 100  100=ð1 þ 0:141Þ
¼ 12:36%=three months

Discussion
Summary of ﬁndings and theoretical implications
This study has investigated two main questions: (1) whether JC
interventions are eﬀective and under which conditions, and (2)
what is the ﬁnancial impact of JC interventions on companies
that implement them? Our analysis indicated statistically signiﬁcant and small eﬀects of interventions on JC and two of its
components, seeking challenges and reducing demands. Our
results also indicated positive, small, and signiﬁcant eﬀects on
work engagement and contextual performance. There were
no statistically signiﬁcant eﬀects on seeking resources, task
performance, and adaptive performance. Therefore, the
answer to the ﬁrst question is (at least partially) aﬃrmative:
JC interventions are eﬀective in increasing JC, work engagement, and contextual performance. Almost all the results were
based on heterogeneous data. Thus, we also tried to ﬁnd out
whether speciﬁc features of the various interventions are
associated with a higher impact on outcomes. What we
found was that the eﬀect on work engagement was signiﬁcantly moderated by the type of objective participants had to
set. Those who set objectives which combined individual and
organizational needs reported a moderate level of engagement, as compared with participants who set goals related
solely to their own needs, for which the eﬀect was small.
Another ﬁnding was the signiﬁcant eﬀect of employees’ occupation on task performance; interventions produced signiﬁcant, small to moderate and homogeneous increases in task
performance for healthcare employees, but not for teachers.
Regarding the second question, our utility analysis based
on the eﬀect of JC interventions on performance indicates
substantial beneﬁts regarding dollar value increases in output,
the percentage increase in output, and reduced labour costs
in the ﬁeld of medical care. Interventions will lead to an
increase of $2,310/three months/employee in revenue from
improved performance for the next three months following
the intervention and a 14.10% increase in output (or to
a 12.36% decrease in labour costs) for the next three months.
Our break-even analysis suggested that the cost of the intervention per employee should not exceed between $2,350 (for
an annual salary of $50,000) and $940 (for an annual salary of
$20,000). As noted, in performing these analyses, we selected
the most reliable eﬀect (i.e., statistically signiﬁcant and homogeneous) obtained for task performance, namely the eﬀect on
healthcare staﬀ. Yet, to cautiously interpret these results one
must also acknowledge that the number of studies that provided these data was very small (k = 3), all were conducted in
the Netherlands, and two came from the same team of investigators (i.e., Gordon et al., 2018; Study 1 and Study 2).
Regarding theoretical implications, the data support the indirect eﬀect of JC behaviours on performance through employee
engagement. This result brings additional evidence in favour of
the JD-R model, showing that, as predicted by Bakker and
Demerouti (2014), when employees are encouraged to craft their
jobs, they will also report a higher level of work engagement and,

14

B. T. OPREA ET AL.

consequently, elevated levels of performance. This indirect eﬀect
reﬂects the presumed mediational process that links JC with
performance and has the advantage (as compared to prior similar
results) to be based on experimental ﬁndings. However, it is
important to mention that all the data were collected at the
same time, namely at post-intervention. Stronger evidence of
the actual temporal sequencing that is suggested by this mediation would have been provided if we had access to multiple
measurements after the interventions. This way we could have
tested if the changes in post-test (T1) JC behaviours are related
with changes in follow-up (T3) performance via the mediation of
the follow-up changes in work engagement (T2). Considering this
limitation, we also tested the indirect eﬀect of the three variables
in all their possible combinations (each of them subsequently
taking the roles of independent variable, mediator, or dependent
variable). The only signiﬁcant mediated relationship remained the
one stipulated by the JD-R model, a fact that oﬀers more robustness to these results. There are also other limitations regarding the
tested indirect eﬀect which need to be considered while interpreting the result, i.e., it is based on a very small sample of eﬀects
(k = 6), the path between JC and work engagement was partially
signiﬁcant, and the eﬀect on overall performance was highly
inconsistent.

Practical implications
From a practical point of view, if we compare our results with
those revealed on other types of interventions, JC programs
are similarly eﬀective in increasing work engagement
(g = 0.31, 95% CI [0.14, 0.50]), as compared to health promotion (g = 0.14, 95% CI [0.02, 0.26]), leadership trainings
(g = 0.14, 95% CI [0.01, 0.30]), interventions that directly aim
to increase job resources (g = 0.40, 95% CI [–0.04, 0.84]) and
personal resources (g = 1.00, 95% CI [–0.20, 2.20]) (see Knight,
Patterson, & Dawson, 2017). The conﬁdence interval of the
eﬀect size for JC interventions overlaps with the ones metaanalytically obtained by Knight et al. (2017) for the other
interventions. Therefore, stimulating JC behaviours is one of
the eﬀective strategies that organizations can use to increase
employee engagement. During JC interventions, participants
analyse their previous workplace behaviours and their impact
on wellbeing and performance. Afterwards, they set goals and
plan new behaviours in order to increase resources and challenges and to boost work engagement and performance (e.g.,
Demerouti et al., 2017; Van den Heuvel et al., 2015). Our
results also show that JC programs which include organizational deﬁned objectives, in addition to the individual crafting
goals, are more eﬀective in increasing work engagement. The
activity of crafting a job enhances employees’ eﬀorts to learn
and engage their capabilities, but without being sustained and
supported, their eﬀects would not last in time (Harju, Hakanen,
& Schaufeli, 2016). Therefore, our ﬁndings on the importance
of job crafting objective(s) should be taken into consideration
from a practical point of view, but cautiously, as only two
samples belonging to the same author (Gordon et al., 2018),
out of a total of nine, used the method of combined objectives. By combining the needs and desires of the employee
with speciﬁc organizational goals, the employee can beneﬁt

from the recognition of achieving an objective, most likely
linked to his job performance and receive feedback.
Considering the impact on performance, JC interventions
enhance the task performance of healthcare employees; the eﬀect
is smaller than the one of organizational training (d = 0.62, 95% CI
[0.05, 1.19]) (Arthur, Bennett, Edens, & Bell, 2003), but similar to the
eﬀect of goal setting (d = 0.46) (see Schmidt, 2013). However, it is
important to note that this result applies only to healthcare professionals and the eﬀect sizes of organizational training and goal
setting are independent of the occupation of the participants in
the interventions. JC interventions increase performance by
encouraging employees to adjust their job characteristics – the
mechanism by which these interventions increase performance is
diﬀerent from the one used in training (acquiring knowledge,
learning new behaviours) and in goal setting (focus, eﬀort, persistence), so we expect JC interventions to have an incremental
eﬀect on performance, beyond existing interventions. Moreover,
JC interventions have a small but statistically signiﬁcant eﬀect on
contextual performance. Existing literature reviews on contextual
performance do not even mention interventions to increase organizational citizenship behaviours (LePine, Erez, & Johnson, 2002;
Podsakoﬀ, MacKenzie, Paine, & Bachrach, 2000). Yet, the data
show an association between high-performance HR practices
and service-oriented organizational citizenship behaviours (Sun,
Aryee, & Law, 2007). Thus, JC interventions represent a new
human resources practice that companies can use to increase
this important component of contextual performance. Finally, JC
interventions do not alter adaptive performance. These results
may be explained by the fact that in one of the studies, the impact
on adaptive performance was tested in the context of organizational change due to austerity measures. These interventions do
not seem to be a practical solution in stimulating adaptive performance under austere conditions. In conclusion, practitioners can
implement JC interventions to increase task performance in
healthcare settings and contextual performance in general.
The key practical implication of our study is given by the results
of the utility analysis. First, it oﬀers practitioners a mean to communicate the ﬁnancial value of these types of interventions, which
can convince managers to implement such programs in their
companies. As far as we know, it is the ﬁrst time when the ﬁnancial
value of proactive behaviours at work is highlighted. This is an
essential step in increasing the credibility of research into proactive behaviours at work and of interventions that stimulate them.
In the modern business environment, implementing such interventions can be a signiﬁcant competitive advantage that companies may ignore in the absence of evidence showing ﬁnancial
beneﬁts. This utility analysis can create more awareness about JC
and may increase the investments of companies in JC interventions. Also, it may raise interest in proactive behaviours in general
and in their outcomes for organizations. JC is just one of the types
of proactive behaviours in which employees can get involved
(Crant, 2000; Grant & Parker, 2009; Hornung et al., 2010). This
estimation of their ﬁnancial impact may stir the curiosity of more
researchers to conduct similar studies also regarding other proactive behaviours, such as identifying opportunities for improvement, positively challenging the status quo or problem
prevention. Accordingly, such pragmatic translation of the interventions’ eﬀectiveness could tighten the gap between scientists
and practitioners.

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

Limitations
Our meta-analysis has several limitations. Firstly, the number
of included studies was rather low. The concept of JC is
relatively new (Wrzesniewski & Dutton, 2001), and quantitative
measurement methods have emerged only recently (Tims
et al., 2012). Therefore, developing and testing JC interventions has only been possible in recent years. The lack of
studies in which interventions were tested is not speciﬁc to
JC, other meta-analyses in organizational psychology being
characterized by the same limitation (e.g., Knight et al., 2017;
Maricuţoiu, Sava, & Butta, 2016). The small number of studies
reduces conﬁdence in the conclusions and impedes the testing of a broader palette of moderators.
Secondly, in most studies, performance was measured
using participants’ self-ratings of task performance (e.g., Van
Wingerden et al., 2016). To draw more valid conclusions,
objective measurements of performance before and after the
interventions are needed. For example, Gordon et al. (2018)
found a signiﬁcant eﬀect of a JC intervention for individual
performance (self-reports), but not for objective measurements of performance (percentage of old patients that had
been screened by the medical specialists and nurses). These
results indicate that scientists need to carry out more studies
in which objective measurements are used to determine the
eﬀectiveness of the interventions.
Thirdly, this meta-analysis considered only three outcomes
(JC behaviours, job performance, and work engagement).
However, cross-sectional and longitudinal studies on JC also
revealed other relevant consequences for organizations, such
as better person-job ﬁt (e.g., Tims, Derks, & Bakker, 2016), and
an increase in customer satisfaction and loyalty (Siddiqi, 2015).
Measuring such outcomes can highlight additional mechanisms through which JC interventions inﬂuence performance.
Also, in the case of customer satisfaction and loyalty, the
results can provide more objective data on the practical
impact of JC interventions.
Fourthly, majority of the studies included in the metaanalysis had very short-term follow-ups, therefore impeded
us to estimate the long-term eﬀectiveness and utility of the
interventions. Studies that are conducted over longer periods
of time can indicate when the eﬀect disappears and, thus at
what time intervals the intervention needs to be repeated in
order to maintain employee JC behaviours. Moreover, studies
with long-term follow-ups can allow us to easily estimate the
return of investment for JC programs, knowing the time period when the eﬀect on performance still exists, and the size of
the eﬀect in each stage. Such information can lead to more
objective HR decisions.
Overall, the quality (internal validity) of the included studies
was rather unclear. Despite the fact that eleven out of thirteen
studies were assessed with a low risk of bias for at least half of the
internal validity criteria, also eleven out of thirteen had selection
problems. Still, the meta-regression analyses revealed that study
quality was not related to eﬀectiveness. However, to minimize
the risk of internal bias, future studies should ﬁrmly comply with
highly standardized guidelines for designing and reporting trials
for non-pharmacological interventions (e.g., CONSORT; Boutron,
Moher, Altman, Schulz, & Ravaud, 2008).

15

Last but not least, the external validity of the results is
a noticeable liability since most of the studies have been performed in the Netherlands. It makes it hard to extrapolate the
applicability of JC interventions in other cultural settings. There is
a high probability that the results related to job crafting will diﬀer
in other types of cultures. According to Hofstede (1983), the
Netherlands is characterized by individualism, low power distance, femininity, and weak uncertainty avoidance. Considering
that job crafting is a self-initiated proactive behaviour meant to
balance the job demands and job resources in order to increase
the well-being of the employee (Bakker & Demerouti, 2014),
there is a possibility that those cultures which are characterized
by weak uncertainty avoidance, are more open to taking risks
and seeking challenges, as well as looking for achieving results in
their own interest, and to exhibit more crafting behaviours than
those that have a more conservative, group-oriented approach.
A recent study compared the Dutch and the American health
care professionals’ job crafting behaviours (Gordon, Demerouti,
Le Blanc, & Bipp, 2015), and the only cultural diﬀerence was
related to the femininity versus masculinity dimension. The
researchers concluded that in a feminine culture such as the
Netherlands, the job resources are higher, and employees craft
their job by seeking resources, whereas in a masculine culture as
in the US, job demands are higher, and the job crafting behaviours are oriented towards reducing them. Hence, there might
be cross-cultural diﬀerences which point to the need for “crafting” JC interventions to local speciﬁcities.

Future research directions
Considering that job performance was most often measured using
self-report questionnaires, it is essential to use other types of
measurements to draw a more explicit conclusion about the eﬀect
of JC interventions on job performance. In future studies on JC,
researchers can use colleague-ratings of task performance (e.g.,
Bakker et al., 2012), or ratings from supervisors. Also, they can use
customer satisfaction and loyalty (e.g., Siddiqi, 2015), or objective
measurements of productivity and eﬃciency to capture the impact
of interventions on task performance. Beyond that, future studies
may consider diﬀerent variables that can explain the mechanisms
through which JC interventions alter performance, besides work
engagement. Some of these may be person-job ﬁt (Chen, Yen, &
Tsai, 2014; Lu, Wang, Lu, Du, & Bakker, 2014), psychological capital
(Vogt, Hakanen, Brauchli, Jenny, & Bauer, 2016), meaningfulness of
work (Tims et al., 2016), or ﬂourishing (Demerouti, Bakker, & Gevers,
2015). Also, more follow-up measures are needed to capture the
long-term eﬀectiveness of such programs. Future longitudinal
studies will lead to a clearer picture regarding the time period in
which the eﬀect on engagement and performance still exists and,
therefore, to more realistic estimates of the eﬀectiveness and utility
of such interventions. Repeated measures over longer periods of
time after the intervention are also necessary for proper mechanisms of change (mediation) analyses (David & Sava, 2015). These
types of designs are the key for unfolding the processes between
JC behaviours and their correlates.
As already mentioned, most studies have been conducted
in the Netherlands. Therefore, since the cross-cultural ﬁndings
suggest that cultural diﬀerences may have an impact on the
way JC works for diﬀerent employees, it is hard to generalize

16

B. T. OPREA ET AL.

the results. Thus, not only that future trials conducted on
diﬀerent cultures are needed, but also cross-cultural studies
regarding JC behaviours would be insightful. Furthermore, at
a smaller scale, job autonomy is associated with a higher level
of JC (Petrou et al., 2012). Hence, JC interventions may not
work in companies where organizational culture does not
allow a high level of autonomy for employees. Based on the
same reasoning, interventions may not have the same eﬀect
on all employees in the same company. A possible moderator
may be job level (Berg et al., 2010), and future programs
should also consider this variable.
When comparing the Dutch (Petrou et al., 2012) and
American (Wrzesniewski & Dutton, 2001) approach to job
crafting, Le Blanc et al. (2017) argue that the Dutch approach
focuses on behavioural aspects targeting the achievement of
a balance between job demands and job resources, excluding the cognitive dimension of the American approach.
Future intervention programs should also focus on targeting
this dimension, and besides this, future operationalisations
should focus on capturing it. Even though several of the
studies report building the job crafting intervention on the
Michigan Job Crafting Exercise (Berg, Dutton, & Wrzesniewski,
& Bakker, 2010), they operationalized them based on the JDR model (Van Wingerden et al., 2016, 2017a, 2017b, 2017),
thus lacking insights on the actual importance of the cognitive dimension.
One of the most interesting ﬁndings on JC is that it is
characterized by a contagion eﬀect. In a diary study conducted on 55 dyads of co-workers, it was found that JC
behaviours transfer from one employee to another, especially
when employees have a high level of empathy (Peeters, Arts,
& Demerouti, 2016). Also, the imitation of JC behaviours is one
of the mechanisms by which work engagement is transferred
from one employee to another (Bakker, Rodríguez-Muñoz, &
Sanz Vergel, 2016). Future research can investigate the impact
of JC interventions on employees who are not directly
involved in the intervention. Researchers can analyse whether
colleagues of people who have taken part in the program
imitate the new behaviours acquired by their peers and
thereby also reach a higher level of JC and work engagement.
Thus, we can verify if the impact of interventions spreads to
organizations without the need for all employees to be
directly involved. If shown to exist, this crossover eﬀect
would have a massive pragmatic impact since the training
cost will be narrowed to only (some) key employees.
Finally, future studies can investigate the possible negative
eﬀects of JC interventions. For example, by analysing 103
dyads of employees, Tims, Bakker, and Derks (2015b) found
that when one member of the dyad decreases his or her
hindering demands, the other one reports higher levels of
workload and conﬂict, which ultimately leads to burnout.
None of the existing studies analyse the eﬀects of interventions on participants’ colleagues. This is a major gap, as the
beneﬁcial eﬀects of JC interventions could be undermined by
the negative consequences on colleagues or working teams.
Moreover, following the intervention, participants may be
tempted to reduce stressful, but necessary, hindering
demands. Identifying these possible negative eﬀects is an
important step in ﬁnding solutions to prevent them.

Conclusion
Job crafting interventions are a new HRM solution for organizational practitioners who aim to increase employee JC behaviours, work engagement, and contextual performance. These
interventions can be eﬀective in increasing task performance
for healthcare workers, at least for three months after the
interventions. Practitioners may use the results of the utility
analysis to highlight the eﬀectiveness of such solutions, showing that they lead to increases in revenue from the improved
performance or to lower labour costs. From a theoretical point
of view, results bring evidence in favour of the JD-R model
(Bakker & Demerouti, 2014), supporting the predictions that
employees who craft their jobs later report a higher level of
work engagement and, furthermore, elevated levels of performance. JC is just one of the concepts that are associated with
proactive behaviours at work; future research should capture
the impact of other proactive behaviours on company performance and their economic value for organizations.

Acknowledgments
*The ﬁrst two authors contributed equally; their order of authorship is
arbitrary.

Disclosure statement
No potential conﬂict of interest was reported by the authors.

Funding
The work of Andrei Rusu was supported by a grant of the Ministery of
Research and Innovation, CNCS - UEFISCDI, project number PN-III-P1-1.1PD-2016-1912, within PNCDI III.

ORCID
Dragoș Iliescu
Andrei Rusu

http://orcid.org/0000-0002-5958-3920
http://orcid.org/0000-0003-0036-4149

References
Arthur, W., Bennett, W., Edens, P. S., & Bell, S. T. (2003). Eﬀectiveness of
training in organizations: A meta-analysis of design and evaluation
features. Journal of Applied Psychology, 88, 234–245.
Arthur, W., Kyte, T., Villado, A., Morgan, C., & Roop, S. (2011). Introducing
a subject matter expert-based utility analysis approach to assessing the
utility of organizational interventions such as crew resource management training. International Journal of Aviation Psychology, 21, 191–215.
Bakker, A. B., & Demerouti, E. (2014). Job demands-resources theory. In
P. Y. Chen & C. L. Cooper (Eds.), Work and wellbeing: Wellbeing:
A complete reference guide (Volume III; pp. 37–64). Chichester, UK:
Wiley-Blackwell.
Bakker, A. B., & Bal, P. M. (2010). Weekly work engagement and performance: A study among starting teachers. Journal of Occupational and
Organizational Psychology, 83, 189–206.
Bakker, A. B., & Demerouti, E. (2007). The job demands−resources model:
State of the art. Journal of Managerial Psychology, 22, 309–328.
Bakker, A. B., Demerouti, E., & Ten Brummelhuis, L. L. (2012). Work engagement, performance, and active learning: The role of conscientiousness.
Journal of Vocational Behavior, 80, 555–564.

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

Bakker, A. B., Hakanen, J. J., Demerouti, E., & Xanthopoulou, D. (2007). Job
resources boost work engagement, particularly when job demands are
high. Journal of Educational Psychology, 99, 274–284.
Bakker, A. B., Rodríguez-Muñoz, A., & Sanz Vergel, A. I. (2016). Modelling
job crafting behaviours: Implications for work engagement. Human
Relations, 69, 169–189.
Bakker, A. B., Tims, M., & Derks, D. (2012). Proactive personality and job
performance: The role of job crafting and work engagement. Human
Relations, 65, 1359–1378.
Bakker, A. B., van Veldhoven, M., & Xanthopoulou, D. (2010). Beyond the
Demand-Control model: Thriving on high job demands and resources.
Journal of Personnel Psychology, 9, 3–16.
Balducci, C., Fraccaroli, F., & Schaufeli, W. B. (2010). Psychometric properties of the Italian version of the Utrecht Work Engagement Scale
(UWES-9). A Cross-cultural Analysis. European Journal of Psychological
Assessment, 26, 143–149. doi: 10.1027/1015-5759/a000020
Barrick, M. R., Day, D. V., Lord, R. G., & Alexander, R. A. (1991). Assessing the
utility of executive leadership. The Leadership Quarterly, 2, 9–22.
Berg, J. M., Dutton, J. E., & Wrzesniewski, A., & Baker, W. E. (2010). Job
crafting exercise. Ann Arbor, MI: Regents of the University of Michigan.
Retrieved from http://www.jobcrafting.org
Berg, J. M., Wrzesniewski, A., & Dutton, J. E. (2010). Perceiving and
responding to challenges in job crafting at diﬀerent ranks: When
proactivity requires adaptivity. Journal of Organizational Behavior, 31,
158–186.
Borenstein, M., Hedges, L., Higgins, J., & Rothstein, H. (2009). Introduction
to meta-analysis. Chichester, UK: Wiley.
Borenstein, M., Higgins, J., Hedges, L. V., & Rothstein, H. R. (2017). Basics of
meta-analysis: I2 is not an absolute measure of heterogeneity. Research
Synthesis Methods, 8, 5–18.
Boudreau, J. W. (1991). Utility analysis for decisions in human resource
management. In M. D. Dunnette & L. M. Hough (Eds.), Handbook of
industrial and organizational psychology (pp. 621–745). Palo Alto, CA:
Consulting Psychologists Press.
Boudreau, J. W., & Ramstad, P. M. (2002). Strategic I/O psychology and the
role of utility analysis models (CAHRS Working Paper #02-16). Ithaca,
NY: Cornell University, School of Industrial and Labor Relations, Center
for Advanced Human Resource Studies. Retrieved from http://digital
commons.ilr.cornell.edu/cahrswp/57
Boutron, I., Moher, D., Altman, D. G., Schulz, K. F., & Ravaud, F. (2008).
Methods and processes of the CONSORT group: Example of an extension for trials assessing nonpharmacologic treatments. Annals of
Internal Medicine, 148, W–66. .
Cabrera, E. F., & Raju, N. S. (2001). Utility analysis: Current trends and future
directions. International Journal of Selection and Assessment, 9, 92–102.
Cascio, W. F., & Boudreau, J. W. (2011). Investing in people: Financial impact
of human resource initiatives. Upper Saddle River, N.J.: FT Press.
Chen, C.-Y., Yen, C.-H., & Tsai, F. C. (2014). Job crafting and job engagement: The mediating role of person-job ﬁt. International Journal of
Hospitality Management, 37, 21–28.
Christian, M. S., Garza, A. S., & Slaughter, J. E. (2011). Work engagement:
A quantitative review and test of its relations with task and contextual
performance. Personnel Psychology, 64, 89–136.
Cohen, J. (1988). Statistical power analysis for the behavioral sciences
second edition. Hillsdale, NJ: Lawrence Erlbaum Associates,
Publishers.
*Costantini, A., Demerouti, E., Ceschi, A., & Sartori, R. (2018, September).
A job crafting intervention based on the theory of planned behaviour.
Eﬀects on cognitions, behaviour and work engagement. Paper presented at the 13th European Academy of Occupational Health
Psychology Conference, Lisbon, PT. Abstract retrieved from: https://
app.oxfordabstracts.com/stages/211/programme-builder/submission/
45865?backHref=/events/199/programme-builder/view/sort/author&
view=published
Crant, J. M. (2000). Proactive behavior in organizations. Journal of
Management, 26, 435–462.
Daniels, K., Gedikli, C., Watson, D., Semkina, A., & Vaughn, O. (2017). Job
design, employment practices and well-being: A systematic review of
intervention studies. Ergonomics, 60, 1177–1196.

17

David, D., & Sava, F. A. (2015). Designs for studying mediation. In R. Cautin
& S. Lilienfeld (Eds.), The encyclopedia of clinical psychology. Hoboken,
NJ: Wiley-Blackwell. doi: 10.1002/9781118625392.wbecp516
Demerouti, E. (2014). Design your own job through job crafting. European
Psychologist, 19, 237–247.
Demerouti, E., Bakker, A., & Gevers, J. J. (2015). Job crafting and extra-role
behavior: The role of work engagement and ﬂourishing. Journal of
Vocational Behavior, 91, 87–96.
*Demerouti, E., Xanthopoulou, D., Petrou, P., & Karagkounis, C. (2017).
Does job crafting assist dealing with organizational changes due to
austerity measures? Two studies among Greek employees. European
Journal of Work and Organizational Psychology, 26, 574–589.
Dierdorﬀ, E. C., & Aguinis, H. (2018). Expanding job crafting theory beyond
the worker and the job. Management Research: Journal of the
Iberoamerican Academy of Management, 16, 225–247.
*Dubbelt, L. (2016). Women to the top: Discovering facilitating factors for
women’s functioning in minority positions (Doctoral dissertation).
Retrieved from https://pure.tue.nl/ws/portalﬁles/portal/15655949
Egger, M., Smith, G. D., Schneider, M., & Minder, C. (1997). Bias in
meta-analysis detected by a simple, graphical test. BMJ, 315, 629–634.
Ford, J. K., Baldwin, T. T., & Prasad, J. (2018). Transfer of training: The
known and the unknown. Annual Review of Organizational Psychology
and Organizational Behavior, 5, 201–225.
*Gordon, H. J., Demerouti, E., Le Blanc, P. M., Bakker, A. B., Bipp, T., &
Verhagen, M. A. M. T. (2018). Individual job redesign: Job crafting
interventions in healthcare. Journal of Vocational Behavior, 104,
98–114. doi: 10.1016/j.jvb.2017.07.002
Goodman, S. A., & Svyantec, D. J. (1999). Person-organization ﬁt and
contextual performance. Do Shared Values Matter? Journal of
Vocational Behavior, 55, 254–275. doi: 10.1006/jvbe.1998.1682
Gordon, H. J., Demerouti, E., Le Blanc, P. M., & Bipp, T. (2015). Job crafting
and performance of Dutch and American health care professionals.
Journal of Personnel Psychology, 14, 192–202.
Grant, A. M., & Parker, S. K. (2009). Redesigning work design theories: The
rise of relational and proactive perspectives. The Academy of
Management Annals, 3, 317–375.
Griﬃn, M. A., Neal, A., & Parker, S. K. (2007). A new model of work role
performance: positive behavior in uncertain and interdependent contexts. Academy of Management Journal, 50, 327–347. doi: 10.5465/
AMJ.2007.24634438
Gwet, K. L. (2012). Handbook of inter-rater reliability (Third edition).
Gaithersburg: Advanced Analytics, LLC.
Hakanen, J. J., Bakker, A. B., & Demerouti, E. (2005). How dentists cope with
their job demands and stay engaged: The moderating role of job
resources. European Journal of Oral Sciences, 113, 479–487.
Halbesleben, J. R. B., & Wheeler, A. R. (2008). The relative roles of engagement and embeddedness in predicting job performance and intention
to leave. Work & Stress, 22, 242–256.
Harju, L. K., Hakanen, J. J., & Schaufeli, W. B. (2016). Can job crafting reduce
job boredom and increase work engagement? A three-year
cross-lagged panel study. Journal of Vocational Behavior, 95, 11–20.
Hazer, J. T., & Highhouse, S. (1997). Factors inﬂuencing managers’ reactions to utility analysis: Eﬀects of SDy method, information frame, and
focal intervention. Journal of Applied Psychology, 82, 104–112.
Hedges, L. V., & Olkin, I. (1985). Statistical methods for meta-analysis 1st
Edition. Orlando, FL: Academic Press.
Hempel, S., Suttorp, M. J., Miles, J. N., Wang, Z., Maglione, M., Morton, S., . . .
Shekelle, P. G. (2011). Empirical evidence of associations between trial
quality and eﬀect size (Research Report No. 11-EHC045-EF). the Agency
for Healthcare Research and Quality (US): Retrieved fromhttps://eﬀecti
vehealthcare.ahrq.gov/sites/default/ﬁles/pdf/trial-quality-eﬀectevidence_research.pdf
Higgins, J. P., & Green, S. (2011). Cochrane handbook for systematic reviews
of interventions (vol. 4). West Sussex: John Wiley & Sons.
Highhouse, S. (1996). The utility estimate as a communication device:
Practical questions and research directions. Journal of Business and
Psychology, 11, 85–100.
Hofstede, G. (1983). The cultural relativity of organizational practice and
theories. Journal of International Business Studies, 14, 75–89.

18

B. T. OPREA ET AL.

*Holman, D., & Axtell, C. (2016). Can job redesign interventions inﬂuence
a broad range of employee outcomes by changing multiple job characteristics? A quasi-experimental study. Journal of Occupational Health
Psychology, 21, 284–295.
Hornung, S., Rousseau, D. M., Glaser, J., Angerer, P., & Weigl, M. (2010).
Beyond top-down and bottom-up work redesign: Customizing job
content through idiosyncratic deals. Journal of Organizational
Behavior, 31, 187–215.
Hunter, J. E., Schmidt, F. L., & Judiesch, M. K. (1990). Individual diﬀerences
in output variability as a function of job complexity. Journal of Applied
Psychology, 75, 28–42.
Knight, C., Patterson, M., & Dawson, J. (2017). Building work engagement:
A systematic review and meta-analysis investigating the eﬀectiveness
of work engagement interventions. Journal of Organizational Behavior,
38, 792–812.
*Kooij, D. T., van Woerkom, M., Wilkenloh, J., Dorenbosch, L., &
Denissen, J. J. A. (2017). Job crafting towards strengths and interests:
The eﬀects of a job crafting intervention on person-job ﬁt and the role
of age. Journal of Applied Psychology, 102, 971–982.
*Kooij, D. T., van Woerkom, M., & Kuijpers, E. (2018, September). Two job
crafting intervention studies: Increasing person-job ﬁt and work
engagement of aging and busy employees. Paper presented at the
13th European Academy of Occupational Health Psychology Conference,
Lisbon, PT. Abstract retrieved from https://app.oxfordabstracts.com/
stages/211/programme-builder/submission/44950?backHref=/stages/
211/symposium/393/programme
Le Blanc, P. M., Demerouti, E., & Bakker, A. B. (2017). How can I shape my
job to suit me better? Job crafting for sustainable employees and
organizations. In N. Chmiel, F. Fraccaroli, & M. Sverke (Eds.), An introduction to work and organizational psychology: An International perspective (pp. 48–63). Hoboken, NJ: John Wiley & Sons. doi: 10.1002/
9781119168058.ch3
LePine, J. A., Erez, A., & Johnson, D. E. (2002). The nature and dimensionality of organizational citizenship behavior: A critical review and
meta-analysis. Journal of Applied Psychology, 87, 52–65.
Lu, C.-Q., Wang, H.-J., Lu, J.-J., Du, D.-Y., & Bakker, A. B. (2014). Does work
engagement increase person-job ﬁt? The role of job crafting and job
insecurity. Journal of Vocational Behavior, 84, 142–152.
Lyons, P. (2008). The crafting of jobs and individual diﬀerences. Journal of
Business Psychology, 23, 25–36.
Macan, T. H., & Foster, J. (2004). Manager’s reactions to utility analysis and
perceptions of what inﬂuences their decisions. Journal of Business and
Psychology, 19, 241–253.
Maricuţoiu, L. P., Sava, F. A., & Butta, O. (2016). The eﬀectiveness of
controlled interventions on employees’ burnout: A meta-analysis.
Journal of Occupational and Organizational Psychology, 89, 1–27.
Metselaar, E. E. (1997). Assessing the willingness to change: Construction
and validation of the DINAMO. NL: Free University of Amsterdam
(Unpublished doctoral dissertation).
Moher, D., Liberati, A., Tetzlaﬀ, J., & Altman, D. G. (2009). Preferred reporting items for systematic reviews and meta-analyses: The PRISMA
statement. Annals of Internal Medicine, 151, 264–269.
Morris, S. B. (2008). Estimating eﬀect sizes from pretest-posttest-control
group designs. Organizational Research Methods, 11, 364–386.
Nielsen, K., & Abildgaard, J. S. (2012). The development and validation of
a job crafting measure for use with blue-collar workers. Work & Stress,
26, 365–384.
O’Shea, D., Lynch, L., Molina, A., & Cullinane, S. J. (2016). The impact of
a relational job crafting intervention on trust and prosocial behaviours:
A randomised controlled trial. [Word document]. Retrieved from http://
programme.exordo.com/ﬁnt2016/delegates/presentation/14/
Oldham, G. R., & Fried, Y. (2016). Job design research and theory: Past,
present and future. Organizational Behavior and Human Decision
Processes, 136, 20–35.
Parker, S. K., Bindl, U. K., & Strauss, K. (2010). Making things happen:
A model of proactive motivation. Journal of Management, 36,
827–856.
Parker, S. K., Morgeson, F. P., & Johns, G. (2017). One hundred years of
work design research: Looking back and looking forward. Journal of
Applied Psychology, 102, 403–420.

Peeters, M. C. W., Arts, R., & Demerouti, E. (2016). The crossover of job
crafting between coworkers and its relationship with adaptivity.
European Journal of Work and Organizational Psychology, 25, 819–832.
Petrou, P., Demerouti, E., Peeters, M. C. W., Schaufeli, W. B., & Hetland, J.
(2012). Crafting a job on a daily basis: Contextual correlates and the link to
work engagement. Journal of Organizational Behavior, 33, 1020–1141.
Podsakoﬀ, P. M., MacKenzie, S. B., Paine, J. B., & Bachrach, D. G. (2000).
Organizational citizenship behaviors: A critical review of the theoretical
and empirical literature and suggestions for future research. Journal of
Management, 26, 513–563.
Rauschenberger, J. M., & Schmidt, F. L. (1987). Measuring the economic
impact of human resource programs. Journal of Business and
Psychology, 2, 50–59.
Roth, P. L., Bobko, P., & Mabon, H. (2002). Utility analysis: A review and
analysis at the turn of the century. In N. Anderson, D. S. Ones,
H. K. Sinangil, & C. Viswesvaran (Eds.), Handbook of industrial, work
and organizational psychology, Volume 1: Personnel psychology. (pp.
383–384). Thousand Oaks, CA: Sage Publications Ltd.
Rudolph, C. W., Katz, I. M., Lavigne, K. N., & Zacher, H. (2017). Job crafting:
A meta-analysis of relationships with individual diﬀerences, job characteristics, and work outcomes. Journal of Vocational Behavior, 102,
112–138.
Sakuraya, A., Shimazu, A., Imamura, K., Namba, K., & Kawakami, N. (2016).
Eﬀects of a job crafting intervention program on work engagement
among Japanese employees: A pretest-posttest study. BMC Psychology,
4, 49–58.
Schaufeli, W. B., Salanova, M., González-Romá, V., & Bakker, A. B. (2002).
The measurement of engagement and burnout: Journal of Happiness
Studies 3, 71–92.
Schaufeli, W.B., Bakker, A.B., & Salanova, M. (2006). The measurement of
work engagement with a brief questionnaire: a cross-national study.
Educational and Psychological Measurement, 66, 701–16. doi: 10.1177/
0013164405282471
Schmidt, F. L. (2013). The economic value of goal setting to employers. In
E. A. Locke & G. P. Latham (Eds.), New developments in goal and task
performance (pp. 16–20). New York: Routledge.
Schmidt, F. L., Hunter, J. E., Outerbridge, A. N., & Trattner, M. H. (1986). The
economic impact of job selection methods on size, productivity, and
payroll costs of the federal work force: An empirically based
demonstration. Personnel Psychology, 39, 1–29.
Shamseer, L., Moher, D., Clarke, M., Ghersi, D., Liberati, A., Petticrew, M., . . .
Stewart, L. A. (2015). Preferred reporting items for systematic review
and meta-analysis protocols (PRISMA-P) 2015: Elaboration and
explanation. BMJ, 349, g7647.
Siddiqi, M. A. (2015). Work engagement and job crafting of service
employees inﬂuencing customer outcomes. Vikalpa, 40, 277–292.
Slemp, G., Kern, M., & Baker, R. (2017). An empirical evaluation of a job
crafting intervention: Recommendations for future research. In
J. Plomp, M. Tims, & S. Parker (Chairs), (eds.), Crafting job crafting
research: Taking context into account. Academy of Management
Proceedings, 2017. doi: 10.5465/ambpp.2017.15373symposium
Sun, L., Aryee, S., & Law, K. S. (2007). High-performance human resource
practices, citizenship behavior, and organizational performance:
A relational perspective. The Academy of Management Journal, 50, 558–577.
Tims, M., Bakker, A. B., & Derks, D. (2012). The development and validation
of the job crafting scale. Journal of Vocational Behavior, 80, 173–186.
Tims, M., Bakker, A. B., & Derks, D. (2015a). Job crafting and job performance: A longitudinal study. European Journal of Work and
Organizational Psychology, 24, 914–928.
Tims, M., Bakker, A. B., & Derks, D. (2015b). Examining job crafting from an
interpersonal perspective: Is employee job crafting related to the WellBeing of colleagues? Applied Psychology, 64, 727–753.
Tims, M., Bakker, A. B., Derks, D., & van Rhenen, W. (2013). Job crafting at
the team and individual level: Implications for work engagement and
performance. Group and Organization Management, 38, 427–454.
Tims, M., Derks, D., & Bakker, A. B. (2016). Job crafting and its relationships
with person-job ﬁt and meaningfulness: A three-wave study. Journal of
Vocational Behavior, 92, 44–53.
*Van den Heuvel, M., Demerouti, E., & Peeters, M. (2015). The job crafting
intervention: Eﬀects on job resources, self-eﬃcacy, and aﬀective

EUROPEAN JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY

well-being. Journal of Occupational and Organizational Psychology, 88,
511–532.
Vanbelle, E. (2016). Job crafting: An overarching approach (Doctoral dissertation).
Retrieved from: https://elsvanbelle.ﬁles.wordpress.com/2017/06/druk_elsvanbelle-_-phd_job-crafting-an-overarching-approach-ﬁnal-p2912.pdf
*Verelst, L., de Cooman, R., van Laar, C., & Meussen, L. (2018, September). The
work-home interface: Lowering conﬂict and fostering enrichment via a job
crafting micro-intervention. Paper presented at the 13th European Academy of
Occupational Health Psychology Conference, Lisbon, PT. Abstract retrieved from
https://app.oxfordabstracts.com/stages/211/programme-builder/submission/
45865?backHref=/events/199/programme-builder/view/sort/author&view=
published
Vogt, K., Hakanen, J. J., Brauchli, R., Jenny, G. J., & Bauer, G. F. (2016). The
consequences of job crafting: A three-wave study. European Journal of
Work and Organizational Psychology, 25, 353–362.
Van Mersbergen, J. (2012). The test and evaluation of a job crafting intervention in healthcare (Master’s thesis). Retrieved from https://pure.tue.
nl/ws/portalﬁles/portal/47045798
*Van Wingerden, J., Bakker, A. B., & Derks, D. (2016). A test of a job
demands-resources intervention. Journal of Managerial Psychology, 31, 686–701.

19

*Van Wingerden, J., Derks, D., & Bakker, A. B. (2017). The impact of
personal resources and job crafting interventions on work engagement and performance. Human Resource Management, 56, 51–67.
*Van Wingerden, J., Bakker, A. B., & Derks, D. (2017a). The longitudinal
impact of a job crafting intervention. European Journal of Work and
Organizational Psychology, 26, 107–119.
*Van Wingerden, J., Bakker, A. B., & Derks, D. (2017b). Fostering employee
well-being via a job crafting intervention. Journal of Vocational
Behavior, 100, 164–174.
Williams, L. J, & Anderson, S. E. (1991). Job satisfaction and organizational
commitment as predictors or organizational citizenship and in-role
behaviors. Journal Oo Management, 17, 601–617. doi: 10.1177/
014920639101700305
Wrzesniewski, A., & Dutton, J. (2001). Crafting a job: Revisioning employees as active crafters of their work. Academy of Management Review, 26,
179–201.
Xanthopoulou, D., Bakker, A.B., Heuven, E., Demerouti, E., & Schaufeli, W.B.
(2008). Working in the sky: a diary study on work engagement among
ﬂight attendants. Journal of Occupational Health Psychology, 13, 345–
356. doi: 10.1037/1076-8998.13.4.345

